{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfZ48cROmtwvr1uzq0Zg4n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AcidCannon/CMPUT466-Mini-project/blob/master/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MnUkbXCSTaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw0ZqkeBdeLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount google drive to save checkpoints\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSg-PJNBUe0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {}\n",
        "config['training_size'] = 60000\n",
        "config['test_size'] = 5000\n",
        "config['validation_size'] = 5000\n",
        "config['training_shuffle'] = True\n",
        "config['test_shuffle'] = False\n",
        "config['validation_shuffle'] = True\n",
        "config['num_of_classes'] = 10\n",
        "config['device'] = 'gpu'\n",
        "config['algorithm'] = 'Convolutional Neural Network'\n",
        "config['training_batch_size'] = 64\n",
        "config['validation_batch_size'] = 64\n",
        "config['test_batch_size'] = 1\n",
        "config['learning_rate'] = 0.0001\n",
        "config['weight_decay'] = 0.001\n",
        "config['best_epoch'] = -1\n",
        "config['best_accuracy'] = 0\n",
        "config['number_of_epochs'] = 100\n",
        "config['display_progress_per_epoch'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM33T1imUyAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(config):\n",
        "  CIFAR10_training_set = datasets.CIFAR10('data', train=True, download=True, transform=transforms.Compose([\n",
        "                                          transforms.RandomCrop(32, padding=4),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                        ]))\n",
        "  \n",
        "  CIFAR10_test = datasets.CIFAR10('data', train=False, download=True, transform=transforms.Compose([\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                        ]))\n",
        "  \n",
        "  CIFAR10_training_set = torch.utils.data.Subset(CIFAR10_training_set, range(0, config['training_size']))\n",
        "  CIFAR10_test_set = torch.utils.data.Subset(CIFAR10_test, range(0, config['test_size']))\n",
        "  CIFAR10_validation_set = torch.utils.data.Subset(CIFAR10_test, range(config['test_size'], config['test_size'] + config['validation_size']))\n",
        "\n",
        "  train_dataloader = torch.utils.data.DataLoader(CIFAR10_training_set, batch_size=config['training_batch_size'], shuffle=config['training_shuffle'])\n",
        "  valid_dataloader = torch.utils.data.DataLoader(CIFAR10_validation_set, batch_size=config['validation_batch_size'], shuffle=config['validation_shuffle'])\n",
        "  test_dataloader = torch.utils.data.DataLoader(CIFAR10_test_set, batch_size=config['test_batch_size'], shuffle=config['test_shuffle'])\n",
        "  return training_dataloader, test_dataloader, validation_dataloader,"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8cvGdfoYPUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    pass\n",
        "  \n",
        "  def forward(self, x):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5udkmL0YiWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(training_dataloader, test_dataloader, config, device):\n",
        "  model = Net().to(device)\n",
        "  \n",
        "  loss_function = F.cross_entropy\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay = config['weight_decay'])\n",
        "\n",
        "  for epoch in range(1, config['number_of_epochs']+1):\n",
        "    # TRAIN\n",
        "    model.train()\n",
        "    for idx, (data, target) in enumerate(training_dataloader):\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      # set gradient to be zero\n",
        "      optimizer.zero_grad()\n",
        "      # forward propagation\n",
        "      output = model(data)\n",
        "      # compute loss\n",
        "      loss = loss_function(output, target)\n",
        "      # backward propagation\n",
        "      loss.backward()\n",
        "      # weight updation\n",
        "      optimizer.step()\n",
        "    # VALIDATION\n",
        "    if epoch % config['display_progress_per_epoch'] == 0:\n",
        "      model.eval()\n",
        "      validation_loss = 0\n",
        "      correct = 0\n",
        "      # no gradients needed since we are doing validation\n",
        "      with torch.no_grad():\n",
        "        for idx, (data, target) in enumerate(test_dataloader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          # predict / forward propagation\n",
        "          output = model(image)\n",
        "          loss = loss_function(output, target)\n",
        "          # find target label\n",
        "          _, predicted = torch.max(output.data, 1)\n",
        "          correct += (predicted == target).sum()\n",
        "          validation_loss += loss.item()\n",
        "      accuracy = 100*correct/len(test_dataloader.dataset)\n",
        "      print(\"Epoch: {}.\\tAvg.loss: {}.\\tAccuracy: {}%.\".format(epoch, validation_loss/len(test_dataloader.dataset), accuracy))\n",
        "      # checkpoint saving strategy: best validation accuracy\n",
        "      if accuracy > config['best_accuracy']:\n",
        "        config['best_epoch'] = epoch\n",
        "        config['best_accuracy'] = accuracy\n",
        "        torch.save(model.to(torch.device('cpu')), '/content/gdrive/My Drive/checkpoints/model.pt.{}'.format(epoch))\n",
        "        print(\"Checkpoint saved.\\tAt epoch: {}.\\tWith accuracy: {}.\".format(epoch, accuracy))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daaPW8TbfNtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_dataloader, device):\n",
        "  correct = 0\n",
        "  total = len(test_dataloader.dataset)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for idx, (data, target) in enumerate(test_dataloader):\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = model(image)\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      correct += (predicted == target).sum().item()\n",
        "  return 100.*correct/total, correct, total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL31PGxif8n4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(config):\n",
        "  if config['device'] != 'cpu' and torch.cuda.is_available():\n",
        "    config['device'] = torch.device('cuda')\n",
        "    print('Using GPU: {}.'.format(torch.cuda.get_device_name(0)))\n",
        "  else:\n",
        "    config['device'] = torch.device('cpu')\n",
        "    print('Using CPU.')\n",
        "\n",
        "  # training_dataloader\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}