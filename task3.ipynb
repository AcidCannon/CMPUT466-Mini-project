{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4Lh6asvCglghI3rsaWIcZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AcidCannon/CMPUT466-Mini-project/blob/master/task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzybJHQBKjKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QpuRQT7LCi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {}\n",
        "config['training_size'] = 60000\n",
        "config['training_batch_size'] = 128\n",
        "config['training_shuffle'] = True\n",
        "config['device'] = 'gpu'\n",
        "config['generator_learning_rate'] = 0.0002\n",
        "config['generator_weight_decay'] = 0\n",
        "config['discriminator_learning_rate'] = 0.0002\n",
        "config['discriminator_weight_decay'] = 0\n",
        "config['algorithm'] = 'Generative Adversarial Network'\n",
        "config['number_of_epochs'] = 200\n",
        "config['discriminator_real_loss_coe'] = 1.0\n",
        "config['discriminator_fake_loss_coe'] = 1.0\n",
        "config['tracking_progress'] = True\n",
        "config['debug'] = True\n",
        "config['mode'] = 'fresh_start' # 'fresh_start' 'load_and_train' 'test' 'demo'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDrP0S7hXE06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config['mode'] == 'demo':\n",
        "  pass\n",
        "  # load last time trained model and data\n",
        "  for i in range(10, 200+10, 10):\n",
        "    !wget '...'\n",
        "else:\n",
        "  # mount google drive to save checkpoints\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSf9MRLYLXXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(config):\n",
        "  MNIST_training_set = datasets.MNIST(root='data', train=True, download=True, transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5,), (0.5,))\n",
        "                  ]))\n",
        "  \n",
        "  MNIST_training_set = torch.utils.data.Subset(MNIST_training_set, range(0, config['training_size']))\n",
        "\n",
        "  training_dataloader = torch.utils.data.DataLoader(dataset=MNIST_training_set, batch_size=config['training_batch_size'], shuffle=config['training_shuffle'])\n",
        "\n",
        "  return training_dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uihkhkONOex3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.fc1 = nn.Linear(100, 256)\n",
        "    self.fc2 = nn.Linear(256, 512)\n",
        "    self.fc3 = nn.Linear(512, 1536)\n",
        "    self.fc4 = nn.Linear(1536, 784)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2, True)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2, True)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2, True)\n",
        "    return torch.tanh(self.fc4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxXOYlUePwsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.fc1 = nn.Linear(784, 1536)\n",
        "    self.fc2 = nn.Linear(1536, 512)\n",
        "    self.fc3 = nn.Linear(512, 256)\n",
        "    self.fc4 = nn.Linear(256, 1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # using dropout to prevent overfitting, p=0.5\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2, True)\n",
        "    x = F.dropout(x)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2, True)\n",
        "    x = F.dropout(x)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2, True)\n",
        "    x = F.dropout(x)\n",
        "    return torch.sigmoid(self.fc4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utIUbQscSIDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_train(config, data, discriminator_optimizer, discriminator, generator, loss_function):\n",
        "  # set gradient to be zero\n",
        "  discriminator_optimizer.zero_grad()\n",
        "  \n",
        "  real_data = (data.view(-1, 784)).to(config['device'])\n",
        "  real_target = (torch.ones(data.shape[0], 1)).to(config['device'])\n",
        "\n",
        "  # forward propagation for real\n",
        "  output = discriminator(real_data)\n",
        "  # compute loss for real\n",
        "  discriminator_real_loss = loss_function(output, real_target)\n",
        "\n",
        "  fake_data = generator(torch.randn(data.shape[0], 100).to(config['device']))\n",
        "  fake_target = (torch.zeros(data.shape[0], 1)).to(config['device'])\n",
        "\n",
        "  # forward propagation for fake\n",
        "  output = discriminator(fake_data)\n",
        "  # compute loss for fake\n",
        "  discriminator_fake_loss = loss_function(output, fake_target)\n",
        "\n",
        "  # compute total loss as a combination of real loss and fake loss\n",
        "  discriminator_total_loss = config['discriminator_real_loss_coe']*discriminator_real_loss + config['discriminator_fake_loss_coe']*discriminator_fake_loss\n",
        "  \n",
        "  # backward propagation for total loss\n",
        "  discriminator_total_loss.backward()\n",
        "  \n",
        "  # weight updation\n",
        "  discriminator_optimizer.step()\n",
        "  \n",
        "  return discriminator_total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0jpk0GScQIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_train(config, data, generator_optimizer, discriminator, generator, loss_function):\n",
        "  # set gradient to be zero\n",
        "  generator_optimizer.zero_grad()\n",
        "\n",
        "  # let generator generates fake image and see if discriminator can discriminate it\n",
        "  # first forward propagate for generator\n",
        "  fake_data = generator(torch.randn(data.shape[0], 100).to(config['device']))\n",
        "  real_target = (torch.ones(data.shape[0], 1)).to(config['device'])\n",
        "\n",
        "  # then forward propagate for discriminator\n",
        "  output = discriminator(fake_data)\n",
        "\n",
        "  # compute loss for generator\n",
        "  generator_total_loss = loss_function(output, real_target)\n",
        "\n",
        "  # backward propagation for total loss\n",
        "  generator_total_loss.backward()\n",
        "\n",
        "  # weight updation\n",
        "  generator_optimizer.step()\n",
        "\n",
        "  return generator_total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyy-4fgSdd1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(training_dataloader, config, device):\n",
        "  #### MAY MODIFY LATER ####\n",
        "  loss_function = F.binary_cross_entropy\n",
        "  if config['mode'] == 'load_and_train':\n",
        "    discriminator = config['discriminator_loaded']\n",
        "    generator = config['generator_loaded']\n",
        "  elif config['mode'] == 'fresh_start':\n",
        "    discriminator = Discriminator().to(device)\n",
        "    generator = Generator().to(device)\n",
        "  discriminator.train()\n",
        "  generator.train()\n",
        "  discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=config['discriminator_learning_rate'], weight_decay = config['discriminator_weight_decay'])\n",
        "  generator_optimizer = torch.optim.Adam(generator.parameters(), lr=config['generator_learning_rate'], weight_decay=config['generator_weight_decay'])\n",
        "  #### MAY MODIFY END ####\n",
        "  for epoch in range(1, config['number_of_epochs']+1):\n",
        "    discriminator_loss = 0\n",
        "    discriminator_count = 0\n",
        "    generator_loss = 0\n",
        "    generator_count = 0\n",
        "    for idx, (data, target) in enumerate(training_dataloader):\n",
        "      discriminator_loss += discriminator_train(config, data, discriminator_optimizer, discriminator, generator, loss_function)\n",
        "      discriminator_count += 1\n",
        "      generator_loss += generator_train(config, data, generator_optimizer, discriminator, generator, loss_function)\n",
        "      generator_count += 1\n",
        "    print(\"Epoch: {}.\\tGenerator Avg.loss: {}.\\tDiscriminator Avg.loss: {}.\".format(epoch, generator_loss/generator_count, discriminator_loss/discriminator_count))\n",
        "    if config['debug']:\n",
        "      with torch.no_grad():\n",
        "        noise = torch.randn(10, 100).to(config['device'])\n",
        "        generated = generator(noise)\n",
        "\n",
        "        # prepare(reshape) noise to plot\n",
        "        noise = (noise.reshape(-1, 10, 10)).cpu().numpy()\n",
        "        # prepare(reshape) generated image to plot\n",
        "        generated = (generated.reshape(-1, 28, 28)).cpu().numpy()\n",
        "        # plot\n",
        "        ax = []\n",
        "        fig = plt.figure(figsize=(20,20))\n",
        "        fig.subplots_adjust(top=0.4)\n",
        "        fig.suptitle(\"Noise and Generated Images\", fontsize=16, y=0.4)\n",
        "        for image_set, row in [(noise, 2), (generated, 1)]:\n",
        "          for i in range(1, 11):\n",
        "            img = image_set[i-1, :, :]\n",
        "            ax.append(fig.add_subplot(row, 10, i))\n",
        "            plt.imshow(img, cmap='gray')\n",
        "        for a in ax:\n",
        "          a.axis('off')\n",
        "        plt.show()\n",
        "        del ax  \n",
        "    if config['mode'] == 'fresh_start' or config['mode'] == 'load_and_train':\n",
        "      torch.save(generator.state_dict(), '/content/gdrive/My Drive/checkpoints/g.ckpt.{}.pth'.format(epoch))\n",
        "      torch.save(discriminator.state_dict(), '/content/gdrive/My Drive/checkpoints/d.ckpt.{}.pth'.format(epoch))\n",
        "      print('Checkpoint saved.')\n",
        "      if config['tracking_progress']:\n",
        "        f = open('/content/gdrive/My Drive/checkpoints/gan_progress.csv', 'a+')\n",
        "        f.write('{},{}\\n'.format(generator_loss/generator_count, discriminator_loss/discriminator_count))\n",
        "        f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzYM1WTGn2Za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(config):\n",
        "  print('Training set size: {}x{}.'.format(config['training_size'], '1x32x32'))\n",
        "  print('Using algorithm: {}.'.format(config['algorithm']))\n",
        "  print('Running in {} mode.'.format(config['mode']))\n",
        "\n",
        "  if config['device'] != 'cpu' and torch.cuda.is_available():\n",
        "    config['device'] = torch.device('cuda')\n",
        "    print('Using GPU: {}.'.format(torch.cuda.get_device_name(0)))\n",
        "  else:\n",
        "    config['device'] = torch.device('cpu')\n",
        "    print('Using CPU.')\n",
        "\n",
        "  print(\"Running...\")\n",
        "\n",
        "  if config['mode'] == 'test':\n",
        "    generator = Generator().to(config['device'])\n",
        "    discriminator = Discriminator().to(config['device'])\n",
        "\n",
        "    generator.load_state_dict(torch.load('/content/gdrive/My Drive/checkpoints/g.ckpt.pth'))\n",
        "    discriminator.load_state_dict(torch.load('/content/gdrive/My Drive/checkpoints/d.ckpt.pth'))\n",
        "\n",
        "    with torch.no_grad():\n",
        "      noise = torch.randn(10, 100).to(config['device'])\n",
        "      generated = generator(noise)\n",
        "\n",
        "      # prepare(reshape) noise to plot\n",
        "      noise = (noise.reshape(-1, 10, 10)).cpu().numpy()\n",
        "      # prepare(reshape) generated image to plot\n",
        "      generated = (generated.reshape(-1, 28, 28)).cpu().numpy()\n",
        "      # plot\n",
        "      ax = []\n",
        "      fig = plt.figure(figsize=(20,20))\n",
        "      fig.subplots_adjust(top=0.4)\n",
        "      fig.suptitle(\"Noise and Generated Images\", fontsize=16, y=0.4)\n",
        "      for image_set, row in [(noise, 2), (generated, 1)]:\n",
        "        for i in range(1, 11):\n",
        "          img = image_set[i-1, :, :]\n",
        "          ax.append(fig.add_subplot(row, 10, i))\n",
        "          plt.imshow(img, cmap='gray')\n",
        "      for a in ax:\n",
        "        a.axis('off')\n",
        "      plt.show()\n",
        "      del ax   \n",
        "  elif config['mode'] == 'fresh_start':  \n",
        "    train(load_data(config), config, config['device'])\n",
        "  elif config['mode'] == 'load_and_train':\n",
        "    generator = Generator().to(config['device'])\n",
        "    discriminator = Discriminator().to(config['device'])\n",
        "\n",
        "    generator.load_state_dict(torch.load('/content/gdrive/My Drive/checkpoints/g.ckpt.pth'))\n",
        "    discriminator.load_state_dict(torch.load('/content/gdrive/My Drive/checkpoints/d.ckpt.pth'))\n",
        "\n",
        "    config['generator_loaded'] = generator\n",
        "    config['discriminator_loaded'] = discriminator\n",
        "\n",
        "    train(load_data(config), config, config['device'])\n",
        "  elif config['mode'] == 'demo':\n",
        "    with torch.no_grad():\n",
        "      noise = torch.randn(10, 100)\n",
        "      reshaped_noise = noise.numpy().reshape(-1, 10, 10)\n",
        "      fig = plt.figure(figsize=(10, 10))\n",
        "      ax = []\n",
        "      fig.suptitle(\"Noise and Generated Images\", fontsize=16, y=0.6)\n",
        "      for i in range(1, 11):\n",
        "        img = reshaped_noise[i-1, :, :]\n",
        "        ax.append(fig.add_subplot(1, 10, i))\n",
        "        plt.imshow(img, cmap='gray')\n",
        "      for a in ax:\n",
        "        a.axis('off')\n",
        "      plt.show()\n",
        "      del ax\n",
        "\n",
        "    for epoch in range(10, 200+10, 10):\n",
        "\n",
        "      generator = Generator().to(config['device'])\n",
        "      discriminator = Discriminator().to(config['device'])\n",
        "\n",
        "      # do not forget to modify path\n",
        "      generator.load_state_dict(torch.load('/content/gdrive/My Drive/checkpoints/g.ckpt.pth'.format(epoch)))\n",
        "      discriminator.load_state_dict(torch.load('/content/gdrive/My Drive/checkpoints/d.ckpt.pth'.format(epoch)))\n",
        "\n",
        "      with torch.no_grad():\n",
        "        generated = generator(noise.to(config['device']))\n",
        "        generated = (generated.reshape(-1, 28, 28)).cpu().numpy()\n",
        "        ax = []\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        for i in range(1, 11):\n",
        "          img = generated[i-1, :, :]\n",
        "          ax.append(fig.add_subplot(1, 10, i))\n",
        "          plt.imshow(img, cmap='gray')\n",
        "        for a in ax:\n",
        "          a.axis('off')\n",
        "        plt.show()\n",
        "        del ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeW74dlsiHnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run(config)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}